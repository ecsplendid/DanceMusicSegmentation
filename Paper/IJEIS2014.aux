\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{radu}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{Matejka:2013:SIO:2470654.2466149}
\citation{tzanetakis1999framework}
\citation{tzanetakis1999framework}
\citation{eckmann1987recurrence}
\citation{foote1999visualizing,foote1997similarity,foote2000automatic,foote2003media,foote2001visualizing}
\citation{goodwin2004dynamic}
\citation{goodwin2003audio}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Literature Review}{2}{subsection.1.1}}
\citation{hauptmann1998story}
\citation{peiszer2008automatic}
\citation{elaudio}
\@writefile{toc}{\contentsline {section}{\numberline {2}Corpus}{3}{section.2}}
\newlabel{dataset}{{2}{3}{Corpus}{section.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The track length distribution for all three radio shows. The \textit  {bump} of short tracks (less than $3$ minutes) is often introductions or otherwise extraneous.}}{4}{figure.1}}
\newlabel{fig:tracklengths}{{1}{4}{The track length distribution for all three radio shows. The \textit {bump} of short tracks (less than $3$ minutes) is often introductions or otherwise extraneous}{figure.1}{}}
\citation{nyquist1928certain}
\@writefile{toc}{\contentsline {section}{\numberline {3}Human Accuracy}{5}{section.3}}
\newlabel{human_acc}{{3}{5}{Human Accuracy}{section.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Data Handling}{5}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Preprocessing}{5}{subsection.4.1}}
\newlabel{proprocessing}{{4.1}{5}{Preprocessing}{subsection.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Illustration of the `human disagreement' random variable (zoomed in at the bottom), standard deviation $9.13$ seconds. Peaks are visible at intervals of $8$ bars ($\approx 14.8$ seconds) which corroborates the analysis from Denis Goncharov in Section\nobreakspace  {}\ref  {dataset}. }}{5}{figure.2}}
\newlabel{fig:human_muchconfuse}{{2}{5}{Illustration of the `human disagreement' random variable (zoomed in at the bottom), standard deviation $9.13$ seconds. Peaks are visible at intervals of $8$ bars ($\approx 14.8$ seconds) which corroborates the analysis from Denis Goncharov in Section~\ref {dataset}}{figure.2}{}}
\citation{frigo2004fftw}
\citation{tzanetakis1999multifeature}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Feature Extraction}{6}{subsection.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Music}{6}{subsubsection.4.2.1}}
\newlabel{feat_ex}{{4.2.1}{6}{Music}{subsubsection.4.2.1}{}}
\citation{tzanetakis1999framework}
\citation{foote1999visualizing}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Illustration of the effect of normalization parameter $\mathaccentV {hat}05Ec=0.7$ on the values in $S$ on radio show Magic Island $110$. The small raised section on the left correspond to the tracks.}}{7}{figure.3}}
\newlabel{fig:cosine_norm}{{3}{7}{Illustration of the effect of normalization parameter $\hat c=0.7$ on the values in $S$ on radio show Magic Island $110$. The small raised section on the left correspond to the tracks}{figure.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Self Similarity}{7}{subsubsection.4.2.2}}
\newlabel{costmatrix_sec}{{4.2.2}{7}{Self Similarity}{subsubsection.4.2.2}{}}
\citation{scarfe2013long}
\@writefile{toc}{\contentsline {paragraph}{Summation}{8}{section*.2}}
\@writefile{toc}{\contentsline {paragraph}{Symmetry}{8}{section*.3}}
\@writefile{toc}{\contentsline {paragraph}{Static Contiguity}{9}{section*.4}}
\@writefile{toc}{\contentsline {paragraph}{Evolutionary Contiguity}{9}{section*.5}}
\@writefile{toc}{\contentsline {paragraph}{Gaussian}{9}{section*.6}}
\@writefile{toc}{\contentsline {paragraph}{Normalization}{9}{section*.7}}
\@writefile{toc}{\contentsline {paragraph}{Mixing Cost Functions}{10}{section*.8}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Computing Best Segmentation}{10}{section.5}}
\newlabel{best_cost}{{5}{10}{Computing Best Segmentation}{section.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Summation cost matrices for Magic Island episode 110 with an incentive bias $\Omega =1$ and therefore containing disincentives. }}{10}{figure.5}}
\newlabel{fig:cmsumib1}{{5}{10}{Summation cost matrices for Magic Island episode 110 with an incentive bias $\Omega =1$ and therefore containing disincentives}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Summation cost matrices for Magic Island episode 110 with an incentive bias $\Omega =0$ and therefore containing incentives. }}{10}{figure.6}}
\newlabel{fig:cmsumib1}{{6}{10}{Summation cost matrices for Magic Island episode 110 with an incentive bias $\Omega =0$ and therefore containing incentives}{figure.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Confidence Intervals}{11}{section.6}}
\newlabel{sec:confidence-intervals}{{6}{11}{Confidence Intervals}{section.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Posterior Marginal of Song Boundary}{11}{subsection.6.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces A visualization of $log(P(j,s))$ ($\eta =10$) for one of the shows in the test set using... TODO.}}{12}{figure.7}}
\newlabel{fig:posterior3}{{7}{12}{A visualization of $log(P(j,s))$ ($\eta =10$) for one of the shows in the test set using... TODO}{figure.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Posterior Marginal of Song Position}{13}{subsection.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Track Index Confidence}{13}{subsection.6.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Track Time Confidence}{13}{subsection.6.4}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Experiments}{13}{section.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Training Set}{13}{subsection.7.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Tracks Known A Priori}{13}{subsection.7.2}}
\newlabel{sec:}{{7.2}{13}{Tracks Known A Priori}{subsection.7.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.1}Evaluation}{13}{subsubsection.7.2.1}}
\newlabel{eval_crit}{{7.2.1}{13}{Evaluation}{subsubsection.7.2.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The shows randomly selected for inclusion in the \textit  {GitHub training set}.}}{14}{table.1}}
\newlabel{table:githubset}{{1}{14}{The shows randomly selected for inclusion in the \textit {GitHub training set}}{table.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.2}Finding The Best Parameters}{14}{subsubsection.7.2.2}}
\newlabel{sec:findingbestcostmatrix}{{7.2.2}{14}{Finding The Best Parameters}{subsubsection.7.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.3}Results}{14}{subsubsection.7.2.3}}
\newlabel{sec:results}{{7.2.3}{14}{Results}{subsubsection.7.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Histogram of the residuals (errors) between reconstructed and human captured time indices. Apart from obvious noise there appears to be a tendency for the algorithm to place an index slightly earlier. Contig-static cost matrix apparently contained parameters selected through optimization that shifted it to remove some of this effect. }}{14}{figure.8}}
\newlabel{fig:shifthistogram}{{8}{14}{Histogram of the residuals (errors) between reconstructed and human captured time indices. Apart from obvious noise there appears to be a tendency for the algorithm to place an index slightly earlier. Contig-static cost matrix apparently contained parameters selected through optimization that shifted it to remove some of this effect}{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Comparison between our algorithm and the Foote novelty peak finding approach on all of the datasets.}}{15}{figure.10}}
\newlabel{fig:fscores_best}{{10}{15}{Comparison between our algorithm and the Foote novelty peak finding approach on all of the datasets}{figure.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Estimating Segment Count}{15}{section.8}}
\newlabel{sec:trackcount}{{8}{15}{Estimating Segment Count}{section.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Number of tracks estimated correctly a show in the GitHub training set after a genetics algorithm was run to select a new set of configuration parameters.}}{15}{figure.11}}
\newlabel{fig:github_trackestimation}{{11}{15}{Number of tracks estimated correctly a show in the GitHub training set after a genetics algorithm was run to select a new set of configuration parameters}{figure.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces }}{15}{figure.12}}
\newlabel{fig:track_shift}{{12}{15}{}{figure.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces These are the main results for all cost matrices with parameters optimized for the best mean absolute accuracy. The tuple $\langle a,b,c \rangle $ is used to indicate the results where $a$ is the median absolute error in seconds, $b$ the mean absolute error in seconds and $c$ the standard deviation in seconds (see Section\nobreakspace  {}\ref  {sec:results}). The experiment number is in parenthesis.}}{16}{table.2}}
\newlabel{tab:mean-results}{{2}{16}{These are the main results for all cost matrices with parameters optimized for the best mean absolute accuracy. The tuple $\langle a,b,c \rangle $ is used to indicate the results where $a$ is the median absolute error in seconds, $b$ the mean absolute error in seconds and $c$ the standard deviation in seconds (see Section~\ref {sec:results}). The experiment number is in parenthesis}{table.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces These are the main results for all cost matrices with parameters optimized for the best median absolute accuracy.}}{16}{table.3}}
\newlabel{tab:median-results}{{3}{16}{These are the main results for all cost matrices with parameters optimized for the best median absolute accuracy}{table.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9}Summary}{16}{section.9}}
\newlabel{conclusions}{{9}{16}{Summary}{section.9}{}}
\bibstyle{ieeetr}
\bibdata{bib/references,bib/refs}
\bibcite{radu}{{1}{}{{}}{{}}}
\bibcite{Matejka:2013:SIO:2470654.2466149}{{2}{}{{}}{{}}}
\bibcite{tzanetakis1999framework}{{3}{}{{}}{{}}}
\bibcite{eckmann1987recurrence}{{4}{}{{}}{{}}}
\bibcite{foote1999visualizing}{{5}{}{{}}{{}}}
\bibcite{foote1997similarity}{{6}{}{{}}{{}}}
\bibcite{foote2000automatic}{{7}{}{{}}{{}}}
\bibcite{foote2003media}{{8}{}{{}}{{}}}
\bibcite{foote2001visualizing}{{9}{}{{}}{{}}}
\bibcite{goodwin2004dynamic}{{10}{}{{}}{{}}}
\bibcite{goodwin2003audio}{{11}{}{{}}{{}}}
\bibcite{peiszer2008automatic}{{12}{}{{}}{{}}}
\bibcite{elaudio}{{13}{}{{}}{{}}}
\bibcite{nyquist1928certain}{{14}{}{{}}{{}}}
\bibcite{frigo2004fftw}{{15}{}{{}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {10}Acknowledgements}{17}{section.10}}
\newlabel{sec:acknowledgements}{{10}{17}{Acknowledgements}{section.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11}Materials}{17}{section.11}}
\newlabel{sec:materials}{{11}{17}{Materials}{section.11}{}}
\bibcite{tzanetakis1999multifeature}{{16}{}{{}}{{}}}
\bibcite{scarfe2013long}{{17}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces An illustration of the similarity matrix $S$ with the actual indices drawn on with white crosses, and our reconstructed indices indicated with the black dotted lines. There are examples here of evolutionary repetition ($t=500,\ldots  ,550$), static contiguity everywhere where there is solid black, and symmetry on the middle two tracks.}}{19}{figure.4}}
\newlabel{fig:simmatrix}{{4}{19}{An illustration of the similarity matrix $S$ with the actual indices drawn on with white crosses, and our reconstructed indices indicated with the black dotted lines. There are examples here of evolutionary repetition ($t=500,\ldots ,550$), static contiguity everywhere where there is solid black, and symmetry on the middle two tracks}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Comparison of the $F_1$ scores against time thresholds on the $4$ data sets.}}{20}{figure.9}}
\newlabel{fig:fscores_breakdown}{{9}{20}{Comparison of the $F_1$ scores against time thresholds on the $4$ data sets}{figure.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Results for stochastic optimization (evolutionary algorithm) search of parameter space. Note that the search space $T$ was limited to a minimum of $3$ seconds to save computation time. }}{21}{table.4}}
\newlabel{tab:parameters}{{4}{21}{Results for stochastic optimization (evolutionary algorithm) search of parameter space. Note that the search space $T$ was limited to a minimum of $3$ seconds to save computation time}{table.4}{}}
